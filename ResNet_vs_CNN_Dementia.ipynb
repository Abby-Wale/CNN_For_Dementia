{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abby-Wale/CNN_For_Dementia/blob/main/ResNet_vs_CNN_Dementia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqWPj0k-aL0z"
      },
      "source": [
        "# deep-learning-project\n",
        "\n",
        "Use the \"Run\" button to execute the code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPb7pVWXaL03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d206692a-453a-4054-d915-4f5e5000135d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/68.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.6/68.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for uuid (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install opendatasets --upgrade --quiet\n",
        "!pip install jovian --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ea2TJctWaWLe"
      },
      "outputs": [],
      "source": [
        "import opendatasets as od\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as tt\n",
        "from torch.utils.data import random_split\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "import math\n",
        "import shutil\n",
        "import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import random\n",
        "import jovian"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RHxYD48ajtN",
        "outputId": "9722aeba-cf34-442e-8811-db2561effc14"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username:"
          ]
        }
      ],
      "source": [
        "dataset_url = 'https://www.kaggle.com/datasets/sachinkumar413/alzheimer-mri-dataset/download?datasetVersionNumber=1'\n",
        "od.download(dataset_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-rZIN4_asyF"
      },
      "outputs": [],
      "source": [
        "dementia_data = '/content/alzheimer-mri-dataset/Dataset'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PRI-jRsbJa6"
      },
      "outputs": [],
      "source": [
        "for cls in os.listdir(dementia_data):\n",
        "    print(cls, ':', len(os.listdir(dementia_data + '/' + cls)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0OAW0HAcfQp"
      },
      "outputs": [],
      "source": [
        "dataset = ImageFolder(dementia_data)\n",
        "len(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOZzlpWOe2HN"
      },
      "outputs": [],
      "source": [
        "dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGBqEjEBe6xp"
      },
      "outputs": [],
      "source": [
        "os.listdir(dementia_data)\n",
        "\n",
        "\"\"\"the code below does the same as above\"\"\"\n",
        "\n",
        "dataset.classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95gyMUfcfB2x"
      },
      "outputs": [],
      "source": [
        "\"\"\"This code snippet involves retrieving an image and its \n",
        "corresponding label from a dataset object. The image and \n",
        "label are assigned to variables `img` and `label`. Then the\n",
        " retrieved image is displayed using `imshow()` function from the \n",
        " `matplotlib.pyplot` library. The resulting image is displayed \n",
        " in the Jupyter notebook output cell.\"\"\"\n",
        "\n",
        "img, label = dataset[120]\n",
        "plt.imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZWlBwT_fLvx"
      },
      "outputs": [],
      "source": [
        "\"\"\"This code initializes an `ImageFolder` object named `dataset` \n",
        "that contains a collection of images. The images are loaded from \n",
        "a directory `dementia_data`. A series of image transformations \n",
        "are applied to each image using `Compose` from \n",
        "`torchvision.transforms`. The transformations include resizing, \n",
        "random cropping, and converting the image to a tensor.\n",
        "\"\"\"\n",
        "\n",
        "dataset = ImageFolder(dementia_data, tt.Compose([tt.Resize(64),\n",
        "                                                 tt.RandomCrop(64),\n",
        "                                                 tt.ToTensor()]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYugHZ4WfxLG"
      },
      "outputs": [],
      "source": [
        "img, label = dataset[120]\n",
        "plt.imshow(img.permute((1, 2, 0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ybkz_IR-g7fp"
      },
      "outputs": [],
      "source": [
        "\"\"\"This code calculates the size of the training, validation, \n",
        "and testing sets based on the total length of the dataset \n",
        "and the percentage split specified in `val_pct`. \n",
        "The calculated sizes of the training, validation, and \n",
        "testing sets are then printed.\"\"\"\n",
        "val_pct = 0.05\n",
        "val_size = int(val_pct * len(dataset))\n",
        "test_size = int(val_pct * len(dataset))\n",
        "train_size = len(dataset) - (val_size + test_size)\n",
        "\n",
        "train_size, val_size, test_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVOwFrfhhDo1"
      },
      "outputs": [],
      "source": [
        "\"\"\"In this code snippet, `random_split()` function from PyTorch's `torch.utils.data` \n",
        "module is used to split the `dataset` into `train_ds`, `valid_ds` and `test_ds` \n",
        "based on the sizes specified by `train_size`, `val_size`, and `test_size` variables.\n",
        "The lengths of `train_ds`, `valid_ds`, and `test_ds` are then displayed using the \n",
        "`len()` function.\"\"\"\n",
        "\n",
        "train_ds, valid_ds , test_ds = random_split(dataset, [train_size, val_size, test_size])\n",
        "len(train_ds), len(valid_ds), len(test_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5wozDbMr08K1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AhDcwn2ehLp1"
      },
      "outputs": [],
      "source": [
        "\"\"\"These lines of code are creating data loaders for the training, validation, and test datasets. \n",
        "A DataLoader is a PyTorch object that provides an iterable over a dataset, allowing us to access \n",
        "the data in batches. The `train_dl`, `valid_dl`, and `test_dl` are DataLoader objects created \n",
        "using the `train_ds`, `valid_ds`, and `test_ds` datasets, respectively. Each data loader has a \n",
        "batch size of 64, which means that during training, the model will receive input data in batches \n",
        "of 64 images at a time. The `shuffle` argument is set to True only for the training data loader, \n",
        "which means that the order of the images in each batch will be randomized for each epoch of training. \n",
        "The `num_workers` argument is set to 2, which means that two worker processes will be used to load \n",
        "the data in parallel. The `pin_memory` argument is set to True, which means that the data will be \n",
        "loaded into pinned memory, making it faster to transfer the data to the GPU.\"\"\"\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_dl = DataLoader(train_ds, \n",
        "                      batch_size, \n",
        "                      shuffle=True, \n",
        "                      num_workers=2, \n",
        "                      pin_memory=True)\n",
        "\n",
        "valid_dl = DataLoader(valid_ds, \n",
        "                    batch_size, \n",
        "                    num_workers=2, \n",
        "                    pin_memory=True)\n",
        "\n",
        "test_dl = DataLoader(test_ds, \n",
        "                    batch_size, \n",
        "                    num_workers=2, \n",
        "                    pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVU4iiAkhYGZ"
      },
      "outputs": [],
      "source": [
        "\"\"\"The `show_batch` function takes a data loader object (`dl`) as input and displays a batch of \n",
        "images and their corresponding labels. It iterates over the data loader and retrieves a batch \n",
        "of images and their labels. It then uses the `make_grid` function from the `torchvision.utils` \n",
        "module to create a grid of the images. The `imshow` function from the `matplotlib.pyplot` module \n",
        "is used to display the grid of images in a figure with no x and y ticks. \n",
        "The `break` statement ensures that only one batch of images is displayed.\"\"\"\n",
        "\n",
        "def show_batch(dl):\n",
        "    for images, labels in dl:\n",
        "        fig, ax = plt.subplots(figsize=(12, 6))\n",
        "        ax.set_xticks([]); ax.set_yticks([])\n",
        "        ax.imshow(make_grid(images, nrow=16).permute(1, 2, 0))\n",
        "        break\n",
        "show_batch(train_dl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tKQ3BL92fwe"
      },
      "source": [
        "##Defining Base Class\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m15v02APkeJd"
      },
      "outputs": [],
      "source": [
        "\n",
        "class ImageClassificationBase(nn.Module):\n",
        "    def training_step(self, batch):\n",
        "        \"calculate loss for a batch of training data\"\n",
        "        images, labels = batch \n",
        "        out = self(images)                  # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch):\n",
        "        \"calculate loss & accuracy for a batch of validation data\"\n",
        "        images, labels = batch \n",
        "        out = self(images)                    # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
        "        acc = accuracy(out, labels)           # Calculate accuracy\n",
        "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
        "        \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
        "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n",
        "        \n",
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaem4Z3tljvO"
      },
      "source": [
        "##MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlWwCY-slT1t"
      },
      "outputs": [],
      "source": [
        "def conv_block(in_channels, out_channels, pool=False):\n",
        "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n",
        "              nn.BatchNorm2d(out_channels), \n",
        "              nn.ReLU(inplace=True)]\n",
        "    if pool: layers.append(nn.MaxPool2d(2))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "# ResNet9 Model\n",
        "class ResNet9(ImageClassificationBase):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super().__init__()\n",
        "        # Input: 128 x 3 x 64 x 64\n",
        "        self.conv1 = conv_block(in_channels, 64) # 128 x 64 x 64 x 64\n",
        "        self.conv2 = conv_block(64, 128, pool=True) # 128 x 128 x 32 x 32\n",
        "        self.res1 = nn.Sequential(conv_block(128, 128), # 128 x 128 x 32 x 32\n",
        "                                  conv_block(128, 128)) # 128 x 128 x 32 x 32\n",
        "        \n",
        "        self.conv3 = conv_block(128, 256, pool=True) # 128 x 256 x 16 x 16\n",
        "        self.conv4 = conv_block(256, 512, pool=True) # 128 x 512 x 8 x 8 \n",
        "        self.res2 = nn.Sequential(conv_block(512, 512), # 128 x 512 x 8 x 8 \n",
        "                                  conv_block(512, 512)) # 128 x 512 x 8 x 8 \n",
        "        \n",
        "        self.classifier = nn.Sequential(nn.AdaptiveMaxPool2d(1), # 128 x 512 x 1 x 1 \n",
        "                                        nn.Flatten(), # 128 x 512\n",
        "                                        nn.Dropout(0.2),\n",
        "                                        nn.Linear(512, num_classes))\n",
        "        \n",
        "    def forward(self, xb):\n",
        "        out = self.conv1(xb)\n",
        "        out = self.conv2(out)\n",
        "        out = self.res1(out) + out\n",
        "        out = self.conv3(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.res2(out) + out\n",
        "        out = self.classifier(out)\n",
        "        return out\n",
        "\n",
        "# print\n",
        "# class PrintShape(nn.Module):\n",
        "#     def forward(self, x):\n",
        "#         print(x.shape)\n",
        "#         return x\n",
        "\n",
        "# CNN Model\n",
        "class DementiaCNNModel(ImageClassificationBase):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2), # output: 64 x 16 x 16\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2), # output: 128 x 8 x 8\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2), # output: 256 x 4 x 4\n",
        "\n",
        "            nn.Flatten(), \n",
        "            nn.Linear(256*8*8, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 4))\n",
        "        \n",
        "    def forward(self, xb):\n",
        "        return self.network(xb)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = DementiaCNNModel()\n",
        "cnn_model"
      ],
      "metadata": {
        "id": "Jfh944YtTPJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cnn_model.conv2d[0].weight.device"
      ],
      "metadata": {
        "id": "Y6sYta_6UBWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in train_dl:\n",
        "    print('images.shape:', images.shape)\n",
        "    out = cnn_model(images)\n",
        "    print('out.shape:', out.shape)\n",
        "    print('out[0]:', out[0])\n",
        "    break"
      ],
      "metadata": {
        "id": "3Nn22W86UAuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNd61IFFl271"
      },
      "outputs": [],
      "source": [
        "resnet_model = ResNet9(3, len(dataset.classes))\n",
        "resnet_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8oTJJmTmGAI"
      },
      "outputs": [],
      "source": [
        "resnet_model.conv1[0].weight.device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIdYfFG6mXFZ"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()\n",
        "for batch in train_dl:\n",
        "    images, labels = batch\n",
        "    print('images.shape', images.shape)\n",
        "    print('images.device', images.device)\n",
        "    preds = resnet_model(images)\n",
        "    print('preds.shape', preds.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Helper Functions Before Training The Model"
      ],
      "metadata": {
        "id": "JKBTzc_DkJWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"this block helps choose the available accelerator\"\"\"\n",
        "\n",
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "    \n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)"
      ],
      "metadata": {
        "id": "OEH0l5a7kIiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "TaU9nJLal2td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = get_default_device()\n",
        "device"
      ],
      "metadata": {
        "id": "XuACrsyXmMBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl = DeviceDataLoader(train_dl, device)\n",
        "valid_dl = DeviceDataLoader(valid_dl, device)\n",
        "test_dl = DeviceDataLoader(test_dl, device)"
      ],
      "metadata": {
        "id": "QpBp4vNBmf-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7GropfHmkNE"
      },
      "source": [
        "##Training the Models\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, val_loader):\n",
        "    \"\"\"Evaluates the model's performance on the validation set\"\"\"\n",
        "    model.eval()\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(), lr)\n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase \n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "    return history"
      ],
      "metadata": {
        "id": "byAw5BpBnIEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"checking  models and evaluating results again before training\"\"\"\n",
        "\n",
        "# evaluate cnn_model\n",
        "cnn_model = to_device(DementiaCNNModel(), device)\n",
        "cnn_result = evaluate(cnn_model, valid_dl)\n",
        "print(f\"CNN model evaluation: {cnn_result}\")\n",
        "\n",
        "# evaluate resnet_model\n",
        "resnet_model = to_device(ResNet9(3, len(dataset.classes)), device)\n",
        "resnet_result = evaluate(resnet_model, valid_dl)\n",
        "print(f\"ResNet model evaluation: {resnet_result}\")\n"
      ],
      "metadata": {
        "id": "p2Yagc3sq4Wa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 4\n",
        "opt_func = torch.optim.Adam\n",
        "lr = 0.0001"
      ],
      "metadata": {
        "id": "0u9eTxf6tKWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('CNN')\n",
        "cnn_history = fit(num_epochs, lr, cnn_model, train_dl, valid_dl, opt_func)\n",
        "\n",
        "print('\\n')\n",
        "print('ResNet')\n",
        "resnet_history = fit(num_epochs, lr, resnet_model, train_dl, valid_dl, opt_func)\n",
        "\n",
        "# for i in range(num_epochs):\n",
        "#     print(f\"Epoch {i+1}/{num_epochs}, CNN Loss: {cnn_history[i]['val_loss']:.5f}, CNN Acc: {cnn_history[i]['val_acc']:.5f}, ResNet Loss: {resnet_history[i]['val_loss']:.5f}, ResNet Acc: {resnet_history[i]['val_acc']:.5f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "NjFdettowN4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('CNN')\n",
        "cnn_history = fit(num_epochs, lr, cnn_model, train_dl, valid_dl, opt_func)\n",
        "\n",
        "print('\\n')\n",
        "print('ResNet')\n",
        "resnet_history = fit(num_epochs, lr, resnet_model, train_dl, valid_dl, opt_func)\n",
        "# for i in range(num_epochs):\n",
        "#     print(f\"Epoch {i+1}/{num_epochs}, \\n CNN Loss: {cnn_history[i]['val_loss']:.5f}, CNN Acc: {cnn_history[i]['val_acc']:.5f},\\n ResNet Loss: {resnet_history[i]['val_loss']:.5f}, ResNet Acc: {resnet_history[i]['val_acc']:.5f}\")"
      ],
      "metadata": {
        "id": "ZsskDn4k0ISK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('CNN')\n",
        "cnn_history = fit(num_epochs, lr, cnn_model, train_dl, valid_dl, opt_func)\n",
        "\n",
        "print('\\n')\n",
        "print('ResNet')\n",
        "resnet_history = fit(num_epochs, lr, resnet_model, train_dl, valid_dl, opt_func)\n",
        "\n",
        "# for i in range(num_epochs):\n",
        "#     print(f\"Epoch {i+1}/{num_epochs}, \\n CNN Loss: {cnn_history[i]['val_loss']:.5f}, CNN Acc: {cnn_history[i]['val_acc']:.5f},\\n ResNet Loss: {resnet_history[i]['val_loss']:.5f}, ResNet Acc: {resnet_history[i]['val_acc']:.5f}\")"
      ],
      "metadata": {
        "id": "wX6qsQ0Y0IBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('CNN')\n",
        "cnn_history = fit(num_epochs, lr, cnn_model, train_dl, valid_dl, opt_func)\n",
        "\n",
        "print('\\n')\n",
        "print('ResNet')\n",
        "resnet_history = fit(num_epochs, lr, resnet_model, train_dl, valid_dl, opt_func)\n",
        "# for i in range(num_epochs):\n",
        "#     print(f\"Epoch {i+1}/{num_epochs}, \\n CNN Loss: {cnn_history[i]['val_loss']:.5f}, CNN Acc: {cnn_history[i]['val_acc']:.5f},\\n ResNet Loss: {resnet_history[i]['val_loss']:.5f}, ResNet Acc: {resnet_history[i]['val_acc']:.5f}\")"
      ],
      "metadata": {
        "id": "PoRfyt830H0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('CNN')\n",
        "cnn_history = fit(num_epochs, lr, cnn_model, train_dl, valid_dl, opt_func)\n",
        "\n",
        "print('\\n')\n",
        "print('ResNet')\n",
        "resnet_history = fit(num_epochs, lr, resnet_model, train_dl, valid_dl, opt_func)\n",
        "# for i in range(num_epochs):\n",
        "#     print(f\"Epoch {i+1}/{num_epochs}, \\n CNN Loss: {cnn_history[i]['val_loss']:.5f}, CNN Acc: {cnn_history[i]['val_acc']:.5f},\\n ResNet Loss: {resnet_history[i]['val_loss']:.5f}, ResNet Acc: {resnet_history[i]['val_acc']:.5f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "83hetK_z0Hqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('CNN')\n",
        "cnn_history = fit(num_epochs, lr, cnn_model, train_dl, valid_dl, opt_func)\n",
        "\n",
        "print('\\n')\n",
        "print('ResNet')\n",
        "resnet_history = fit(num_epochs, lr, resnet_model, train_dl, valid_dl, opt_func)\n",
        "# for i in range(num_epochs):\n",
        "#     print(f\"Epoch {i+1}/{num_epochs}, \\n CNN Loss: {cnn_history[i]['val_loss']:.5f}, CNN Acc: {cnn_history[i]['val_acc']:.5f},\\n ResNet Loss: {resnet_history[i]['val_loss']:.5f}, ResNet Acc: {resnet_history[i]['val_acc']:.5f}\")"
      ],
      "metadata": {
        "id": "vH468wPK0HMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('CNN')\n",
        "cnn_history = fit(num_epochs, lr, cnn_model, train_dl, valid_dl, opt_func)\n",
        "\n",
        "print('\\n')\n",
        "print('ResNet')\n",
        "resnet_history = fit(num_epochs, lr, resnet_model, train_dl, valid_dl, opt_func)\n"
      ],
      "metadata": {
        "id": "0paIOt5-xxhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1KLTFwKkRY8i"
      },
      "outputs": [],
      "source": [
        "def plot_accuracies(history, ax, name):\n",
        "    accuracies = [x['val_acc'] for x in history]\n",
        "    ax.plot(accuracies, '-x')\n",
        "    ax.set_xlabel('epoch')\n",
        "    ax.set_ylabel('accuracy')\n",
        "    ax.set_title(f'{name}: Acc vs epochs')\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
        "plot_accuracies(cnn_history, ax1, 'CNN')\n",
        "plot_accuracies(resnet_history, ax2, 'ResNet')\n",
        "fig.tight_layout(pad=3.0)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# plot_accuracies(cnn_history), plot_accuracies(resnet_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zoX-uPqVDWW"
      },
      "outputs": [],
      "source": [
        "def plot_losses(history, ax):\n",
        "    train_losses = [x.get('train_loss') for x in history]\n",
        "    val_losses = [x['val_loss'] for x in history]\n",
        "    ax.plot(train_losses, '-bx')\n",
        "    ax.plot(val_losses, '-rx')\n",
        "    ax.set_xlabel('epoch')\n",
        "    ax.set_ylabel('loss')\n",
        "    ax.legend(['Training', 'Validation'])\n",
        "    ax.set_title('Loss vs. No. of epochs')\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "plot_losses(cnn_history, ax1)\n",
        "plot_losses(resnet_history, ax2)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aognG5tzVFUB"
      },
      "outputs": [],
      "source": [
        "print(\"CNN last output: \", cnn_history[-1])\n",
        "print(\"ResNet last output: \", resnet_history[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmzqTUCPiP_I"
      },
      "outputs": [],
      "source": [
        "# jovian.reset()\n",
        "# jovian.log_dataset(image_size=64)\n",
        "# jovian.log_hyperparams(batch_size=128, \n",
        "#                        arch='ResNet9', \n",
        "#                        epochs=[5, 5, 5, 5], \n",
        "#                        lrs=[0.001, 0.001, 1e-4, 1e-4],\n",
        "#                        opt=['Adam', 'Adam', 'Adam', 'SGD'])\n",
        "# jovian.log_metrics(train_loss=history[-1]['train_loss'],\n",
        "#                    val_acc=history[-1]['val_acc'],\n",
        "#                    val_loss=history[-1]['val_loss'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "myZd0N9LiZfG"
      },
      "outputs": [],
      "source": [
        "def predict_image(img, model, classes):\n",
        "    # Convert to a batch of 1\n",
        "    xb = to_device(img.unsqueeze(0), device)\n",
        "    # Get predictions from model\n",
        "    yb = model(xb)\n",
        "    # Pick index with highest probability\n",
        "    _, preds  = torch.max(yb, dim=1)\n",
        "    # Retrieve the class label\n",
        "    return classes[preds[0].item()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6896kkTiohf"
      },
      "outputs": [],
      "source": [
        "def show_image_prediction(img, label, model):\n",
        "    plt.imshow(img.permute((1, 2, 0)))\n",
        "    pred = predict_image(img, model, dataset.classes)\n",
        "    print('Target:', dataset.classes[label])\n",
        "    print('Prediction:', pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzNbFNIqitU7"
      },
      "outputs": [],
      "source": [
        "show_image_prediction(*test_ds[100], resnet_model)\n",
        "show_image_prediction(*test_ds[100], cnn_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTv6MTYDixxZ"
      },
      "outputs": [],
      "source": [
        "show_image_prediction(*test_ds[10], resnet_model)\n",
        "show_image_prediction(*test_ds[10], cnn_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dV-HsqZZi3aS"
      },
      "outputs": [],
      "source": [
        "show_image_prediction(*test_ds[230], resnet_model)\n",
        "show_image_prediction(*test_ds[230], cnn_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rw3J9WqDi313"
      },
      "outputs": [],
      "source": [
        "show_image_prediction(*test_ds[5], resnet_model)\n",
        "show_image_prediction(*test_ds[5], cnn_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRz13akni4zL"
      },
      "outputs": [],
      "source": [
        "# torch.save(model.state_dict(), 'dementia-resnet9.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###comments\n",
        "\n",
        "\n",
        "Pooling and Flatten are different concepts while pooling you're reducing the number of elements and selecting a max, min, or average element from a set of multiple elements. On the other hand, flatten just changes the dimension of a list of elements from multiple dimensions to a single dimension, so if there are 12 elements in total after flatten you will also have 12 elements. "
      ],
      "metadata": {
        "id": "6v2Y3XT1dgUc"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}